# 模型中的内存组织

# 概述

在讲解内核中用于组织内存的数据结构之前，考虑到术语并不总是容易理解，所以我们需要先定义几个概念。我们首先考虑NUMA系统。这样，在UMA系统上再介绍这些概念就非常容易了。 

**首先，内存划分为结点。**每个结点关联到系统中的一个处理器，在内核中表示为pg_data_t的实 例(稍后定义该数据结构)。 

**各个结点又划分为内存域，是内存的进一步细分。**例如，对可用于(ISA设备的)DMA操作的内 存区是有限制的。只有前16 MiB适用，还有一个高端内存区域无法直接映射。在二者之间是通用的“普 通”内存区。因此一个结点最多由3个内存域组成。内核引入了下列常量来区分它们 。

![img](https://p2onpu7kg4.feishu.cn/space/api/box/stream/download/asynccode/?code=ZmY0OWIzNjIwZTAwYTNjZmZjNTdkMjczYzk4OTY4ZDhfaWI4cHhzR2liRm1hYzY4aEFxQ3I4ZTVhQ3ZSTFZ3NUNfVG9rZW46SU5waGJSUncyb1FHS3N4bmlwOGNjOUd1bldjXzE3MTI1ODc5NzI6MTcxMjU5MTU3Ml9WNA)

各个内存域都关联了一个数组，用来组织属于该内存域的物理内存页(**内核中称之为页帧**)。对 每个页帧，都分配了一个**struct page**实例以及所需的管理数据。

各个内存结点保存在一个单链表中，供内核遍历。

**出于性能考虑，在为进程分配内存时，内核总是试图在当前运行的CPU相关联的NUMA结点上进行**。但这并不总是可行的，例如，该结点的内存可能已经用尽。对此类情况，每个结点都提供了一个 备用列表(借助于struct zonelist)。该列表包含了其他结点(和相关的内存域)，可用于代替当 前结点分配内存。列表项的位置越靠后，就越不适合分配。 

根据编译时的配置，可能无需考虑某些内存域。例如在64位系统中，并不需要高端内 存域。如果支持了只能访问4 GiB以下内存的32位外设，才需要DMA32内存域。 

1. # 数据结构

1. ## 结点管理

1. ### 结点的数据结构 

pg_data_t是用于表示结点的基本元素，定义如下: 

![img](https://p2onpu7kg4.feishu.cn/space/api/box/stream/download/asynccode/?code=YzBhOGY3ZjA4MWYxYjFhYTlkMGYwM2EwOGNkZDQ0MTVfeFFxZ0Jhd1dUaDE5Z3RKaUoxTnplYWhwMWZFREhmdGJfVG9rZW46WG1XQWJzdUxab0JGVWZ4Nkk3RmNvUTlvbkViXzE3MTI1ODc5NzI6MTcxMjU5MTU3Ml9WNA)

- **node_zones**是一个数组，包含了结点中各内存域的数据结构。 
- **node_zonelists**指定了备用结点及其内存域的列表，以便在当前结点没有可用空间时，在备用结点分配内存。 
- 结点中不同内存域的数目保存在**nr_zones**。 
- **node_mem_map**是指向page实例数组的指针，用于描述结点的所有物理内存页。它包含了结点 中所有内存域的页。 
- **bdata**指向自举内存分配器数据结构的实例。 在系统启动期间，内存管理子系统初始化之前，内核也需要使用内存(另外，还必须保留部分内存用于初始化内存管理子系统)。为解决这个问题，内核使用了3.4.3节讲解的自举内存分配器(boot memory allocator)。
- **node_start_pfn**是该NUMA结点第一个页帧的逻辑编号。系统中所有结点的页帧是依次编号的，每个页帧的号码都是全局唯一的(不只是结点内唯一)。  node_start_pfn在UMA系统中总是0，因为其中只有一个结点，因此其第一个页帧编号总是0。 node_present_pages指定了结点中页帧的数目，而node_spanned_pages则给出了该结点以 页帧为单位计算的长度。二者的值不一定相同，因为结点中可能有一些空洞，并不对应真正的页帧。 
- **node_id**是全局结点ID。系统中的NUMA结点都从0开始编号。 
- **pgdat_next**连接到下一个内存结点，系统中所有结点都通过单链表连接起来，其末尾通过空指针标记。
- **kswapd_wait**是交换守护进程(swap daemon)的等待队列，在将页帧换出结点时会用到(第 18章会详细讨论该过程)。kswapd指向负责该结点的交换守护进程的task_struct。kswapd_ max_order用于页交换子系统的实现，用来定义需要释放的区域的长度(我们当前不感兴趣)。  

1. ### 节点的状态管理

如果系统中结点多于一个，内核会维护一个位图，用以提供各个结点的状态信息。状态是用位掩 码指定的，可使用下列值: 

![img](https://p2onpu7kg4.feishu.cn/space/api/box/stream/download/asynccode/?code=ZGI2ZmZlYzVhZmI1N2U3ZTc1ZGFlNGYyNzZiZDI0NGZfTVFyazk1anB6eVI3RE15MzE5QTJrS0ROanU0cTM4elpfVG9rZW46SXJ3WmJxRE05bzlQYnZ4clBEVGNlYm1wbnZnXzE3MTI1ODc5NzI6MTcxMjU5MTU3Ml9WNA)

- 状态**N_POSSIBLE**、**N_ONLINE**和**N_CPU**用于CPU和内存的热插拔，在本书中不考虑这些特性。
- 对 内存管理有必要的标志是**N_HIGH_MEMORY**和**N_NORMAL_MEMORY**。
- 如果结点有普通或高端内存则使用 **N_HIGH_MEMORY**，仅当结点没有高端内存才设置N_NORMAL_MEMORY。

两个辅助函数用来设置或清除位域或特定结点中的一个比特位:

![img](https://p2onpu7kg4.feishu.cn/space/api/box/stream/download/asynccode/?code=YzdiZjg1YmQ5ZDc2NzViODRmNWJmM2Q5ZDU4M2I1OTRfU0FqTWNlQU1tY1l3cGdVWlZTS3VsUnJYOVlGdlRoMDdfVG9rZW46S2wzNmJ2ZHpLbzkwUUd4VDVPM2NWWWx6bkVmXzE3MTI1ODc5NzI6MTcxMjU5MTU3Ml9WNA)

此外，宏for_each_node_state(__node, __state)用来迭代处于特定状态的所有结点，而for_ each_online_node(node)则迭代所有活动结点。 

如果内核编译为只支持单个结点(即使用平坦内存模型)，则没有结点位图，上述操作该位图的 函数则变为空操作。 

1. ## 内存域 

1. ### 内存域概述

**内核使用zone结构来描述内存域。**

该结构比较特殊的方面是它由ZONE_PADDING分隔为几个部分。

这是因为对zone结构的访问非常 频繁。在多处理器系统上，通常会有不同的CPU试图同时访问结构成员。因此使用锁(见第5章)防 止它们彼此干扰，避免错误和不一致。由于内核对该结构的访问非常频繁，因此会经常性地获取该结 9 构的两个自旋锁zone->lock和zone->lru_lock。 

**如果数据保存在CPU高速缓存中，那么会处理得更快速。**高速缓存分为行，每一行负责不同的内 存区。内核使用ZONE_PADDING宏生成“填充”字段添加到结构中，以确保每个自旋锁都处于自身的缓存行中。还使用了编译器关键字__cacheline_maxaligned_in_smp，用以实现最优的高速缓存对 齐方式。 

**该结构的最后两个部分也通过填充字段彼此分隔开来**。两者都不包含锁，主要目的是将数据保持 在一个缓存行中，便于快速访问，从而无需从内存加载数据(与CPU高速缓存相比，内存比较慢)。 由于填充造成结构长度的增加是可以忽略的，特别是在内核内存中zone结构的实例相对很少。 

该结构各个成员的语义是什么呢?由于内存管理是内核中一个复杂而牵涉颇广的部分，因此在这 里将该结构所有成员的确切语义都讲解清楚是不太可能的，本章和后续章节相当一部分都会专注于讲 述相关的数据结构和机制。此处只能对即将讨论的问题给予概述，读者姑且浅尝辄止。尽管如此，仍然会出现大量的向前引用。 

1. ### 内存域数据结构

其定义如下: 

![img](https://p2onpu7kg4.feishu.cn/space/api/box/stream/download/asynccode/?code=ZjVhYzA4NTk5MWUzYjg2MjI2NzRiM2ViNTk1ZDdkNWFfSHRzWUxZODNPckRlQnIya2hWWWoyTEppS2ROU3M5NkJfVG9rZW46RVNUVWJ6OWQ3b3I5ZUR4b0FKQmNFYjl1bmVmXzE3MTI1ODc5NzI6MTcxMjU5MTU3Ml9WNA)

**第一部分：**

- **pages_min、pages_high、pages_low**是页换出时使用的“水印”。如果内存不足，内核可以将页写到硬盘。这3个成员会影响交换守护进程的行为。
  - 如果空闲页多于pages_high，则内存域的状态是理想的。
  - 如果空闲页的数目低于pages_low，则内核开始将页换出到硬盘。 
  - 如果空闲页的数目低于pages_min，那么页回收工作的压力就比较大，因为内存域中急需空 闲页。第18章会讨论内核用于缓解此情形的各种方法。 
  - > 这些水印的重要性主要会在第18章讨论，但在3.5.5节就可以初步看到它们的作用了。 
- **lowmem_reserve**数组分别为各种内存域指定了若干页，用于一些无论如何都不能失败的关键 性内存分配。各个内存域的份额根据重要性确定。用于计算各个内存域份额的算法在3.2.2节 讨论。 
- **pageset**是一个数组，用于实现每个CPU的热/冷页帧列表。内核使用这些列表来保存可用于 满足实现的“新鲜”页。但冷热页帧对应的高速缓存状态不同:有些页帧也很可能仍然在高 速缓存中，因此可以快速访问，故称之为热的;未缓存的页帧与此相对，故称之为冷的。下 一节会讨论用于实现该行为特性的struct per_cpu_pageset数据结构。 
- **free_area**是同名数据结构的数组，用于实现伙伴系统。每个数组元素都表示某种固定长度的 一些连续内存区。对于包含在每个区域中的空闲内存页的管理，free_area是一个起点。 此处使用的数据结构自身就很值得讨论一番，3.5.5节深入论述了伙伴系统的实现细节。

 **第二部分：**

- **active_list**是活动页的集合，而inactive_list则不活动页的集合(page实例)。
- **nr_scan_active**和nr_scan_inactive指定在回收内存时需要扫描的活动和不活动页的数目。 
- **pages_scanned**指定了上次换出一页以来，有多少页未能成功扫描。
- **flags**描述内存域的当前状态。允许使用下列标志: 

```C++
<mmzone.h> 
typedef enum {
        ZONE_ALL_UNRECLAIMABLE,
        ZONE_RECLAIM_LOCKED,
        ZONE_OOM_LOCKED,
} zone_flags_t;
```

也有可能这些标志均未设置。这是内存域的正常状态。ZONE_ALL_UNRECLAIMABLE状态出现 在内核试图重用该内存域的一些页时(页面回收，参见第18章)，但因为所有的页都被钉住 而无法回收。例如，用户空间应用程序可以使用mlock系统调用通知内核页不能从物理内存 移出，比如换出到磁盘上。这样的页称之为钉住的。如果一个内存域中的所有页都被钉住， 那么该内存域是无法回收的，即设置该标志。为不浪费时间，交换守护进程在寻找可供回 收的页时，只会简要地扫描一下此类内存域。

 在SMP系统上，多个CPU可能试图并发地回收一个内存域。ZONE_RECLAIM_LOCKED标志可防 止这种情况:如果一个CPU在回收某个内存域，则设置该标志。这防止了其他CPU的尝试。 ZONE_OOM_LOCKED专用于某种不走运的情况:如果进程消耗了大量的内存，致使必要的操 作都无法完成，那么内核会试图杀死消耗内存最多的进程，以获得更多的空闲页。该标志 3 可以防止多个CPU同时进行这种操作。 

内核提供了3个辅助函数用于测试和设置内存域的标志: 

```C++
<mmzone.h> 
void zone_set_flag(struct zone *zone, zone_flags_t flag)
int zone_test_and_set_flag(struct zone *zone, zone_flags_t flag) 
void zone_clear_flag(struct zone *zone, zone_flags_t flag) 
```

zone_set_flag和zone_clear_flag分别用于设置和清除某一标志。zone_test_and_set_ flag首先测试是否设置了给定标志，如果没有设置，则设置该标志。标志的原状态返回给调 用者。 

**第三部分：**

- **vm_stat**维护了大量有关该内存域的统计信息。由于其中维护的大部分信息目前没有多大意义，对该结构的详细讨论则延迟到17.7.1节。现在，只要知道内核中很多地方都会更新其中 的信息即可。辅助函数zone_page_state用来读取vm_stat中的信息: 

> ```C++
> <vmstat.h> 
> static inline unsigned long zone_page_state(struct zone *zone,enum zone_stat_item item)
> ```

> 例如，可以将item参数设置为NR_ACTIVE或NR_INACTIVE，来查询存储在上文讨论的 active_list和inactive_list中的活动和不活动页的数目。而设置为NR_FREE_PAGES则可 以获得内存域中空闲页的数目。 

- **prev_priority**存储了上一次扫描操作扫描该内存域的优先级，扫描操作是由try_to_free_ pages进行的，直至释放足够的页帧(参见3.5.5节和第18章)。读者在第18章会看到，扫描 会根据该值判断是否换出映射的页。 
- **wait_table**、**wait_table_bits**和**wait_table_hash_nr_entries**实现了一个等待队列， 可供等待某一页变为可用的进程使用。该机制的细节将在第14章给出，直观的概念是很好 理解的:进程排成一个队列，等待某些条件。在条件变为真时，内核会通知进程恢复工作。 
- 内存域和父结点之间的关联由**zone_pgdat**建立，zone_pgdat指向对应的pglist_data实例。 
- **zone_start_pfn**是内存域第一个页帧的索引。 
- 剩余的3个字段很少使用，因此置于数据结构末尾。 
  - name是一个字符串，保存该内存域的惯用名称。目前有3个选项可用:Normal、DMA和HighMem。
  - spanned_pages指定内存域中页的总数，但并非所有都是可用的。前文提到过，内存域中可能有一些小的空洞。
  - 另一个计数器(present_pages)则给出了实际上可用的页数目，该计数器的值通常与spanned_pages相同。 

1. ## 内存域水印的计算 

1. ## 冷热页 

1. ### 冷热页的概念

struct zone的pageset成员用于实现冷热分配器(hot-n-cold allocator)。

内核说页是热的，意味着页已经加载到CPU高速缓存，与在内存中的页相比，其数据能够更快地访问。相反，冷页则不在高速缓存中。

在多处理器系统上每个CPU都有一个或多个高速缓存，各个CPU的管理必须是独立的。 

**尽管内存域可能属于一个特定的NUMA结点，因而关联到某个特定的CPU，但其他 CPU的高速缓存仍然可以包含该内存域中的页。最终的效果是，每个处理器都可以访问系 统中所有的页，尽管速度不同。因此，特定于内存域的数据结构不仅要考虑到所属NUMA 结点相关的CPU，还必须照顾到系统中其他的CPU。** 

pageset是一个数组，其容量与系统能够容纳的CPU数目的最大值相同。 

```C++
<mmzone.h> 
    struct zone {
        ...
        struct per_cpu_pageset pageset[NR_CPUS];
        ... 
    }; 
```

NR_CPUS是一个可以在编译时间配置的宏常数。在单处理器系统上其值总是1，针对SMP系统编 译的内核中，其值可能在2和32(在64位系统上是64)之间。 

**该值并不是系统中实际存在的CPU数目，而是内核支持的CPU的最大数目。** 

1. ### 冷热页的数据结构

数组元素的类型为per_cpu_pageset，定义如下: 

```C++
<mmzone.h> 
struct per_cpu_pageset {
    struct per_cpu_pages pcp[2]; /* 索引0对应热页，索引1对应冷页 */ 
} ____cacheline_aligned_in_smp;
```

该结构由一个带有两个数组项的数组构成，第一项管理热页，第二项管理冷页。 有用的数据保存在per_cpu_pages中。 

```C++
<mmzone.h> 
struct per_cpu_pages {
    int count;                    /* 列表中页数 */
    int high;                     /* 页数上限水印，在需要的情况下清空列表 */ 
    int batch;                    /* 添加/删除多页块的时候，块的大小 */ 
    struct list_head list;        /* 页的链表 */ 
 }
```

- **count**记录了与该列表相关的页的数目;
- **high**是一个水印。
  - 如果count的值超出了high，则表明 列表中的页太多了。对容量过低的状态没有显式使用水印:如果列表中没有成员，则重新填充。 
- **list**是一个双链表，保存了当前CPU的冷页或热页，可使用内核的标准方法处理。 

如有可能，CPU的高速缓存不是用单个页来填充的，而是用多个页组成的块。batch是每次添加 页数的一个参考值。 

图3-6说明了在双处理器系统上per-CPU缓存的数据结构是如何填充的。 

![img](https://p2onpu7kg4.feishu.cn/space/api/box/stream/download/asynccode/?code=MWI0MTliM2Q0NzgwODViMzU2ZTBmZjQzMjYyMjYxN2VfZ0hYS1dBYm5FWm5VWGdRRzBrTklQUE5IeUpOUVBXaVBfVG9rZW46WkJjRWJDWVR4b1RUS2d4c2FGMWN1UWdvbmRmXzE3MTI1ODc5NzI6MTcxMjU5MTU3Ml9WNA)

水印的计算以及高速缓存数据结构的初始化将在3.4.2节更详细地讨论。

1. ## 页帧

1. ### 页帧概述

**页帧代表系统内存的最小单位**，对内存中的每个页都会创建struct page的一个实例。

内核程序员需要注意保持该结构尽可能小，因为即使在中等程度的内存配置下，系统的内存同样会分解为大量 的页。例如，IA-32系统的标准页长度为4 KiB，在主内存大小为384 MiB时，大约共有100 000页。就 当今的标准而言，这个容量算不上很大，但页的数目已经非常可观。 

这也是为什么内核尽力保持struct page尽可能小的原因。在典型系统中，由于页的数目巨大， 因此对page结构的小改动，也可能导致保存所有page实例所需的物理内存暴涨。 6

**页的广泛使用，增加了保持结构长度的难度**:内存管理的许多部分都使用页，用于各种不同的用途。内核的一个部分可能完全依赖于struct page提供的特定信息，而该信息对内核的另一部分可能完全无用，该部分依赖于struct page提供的其他信息，而这部分信息对内核的其他部分也可能是完全无用的，等等。 

C语言的联合很适合于该问题，尽管它未能增加struct page的清晰程度。

**考虑一个例子:**一个物理内存页能够通过多个地方的不同页表映射到虚拟地址空间，内核想要跟踪有多少地方映射了该页。为此，struct page中有一个计数器用于计算映射的数目。如果一页用于slub分配器(将整页细 分为更小部分的一种方法，请参见3.6.1节)，那么可以确保只有内核会使用该页，而不会有其他地方 使用，因此映射计数信息就是多余的。因此内核可以重新解释该字段，用来表示该页被细分为多少个 小的内存对象使用。在数据结构定义中，这种双重解释如下所示: 

![img](https://p2onpu7kg4.feishu.cn/space/api/box/stream/download/asynccode/?code=M2MxNTI4OTNkYWVhYzhlZjE2NjlkMmFiMmZiYmQ3MjVfY3dZaUNMclJhVFp0Q1VZaVREa2Q3NDRkaGNSeUFWcDRfVG9rZW46REtLMGJHaDZwb3NGY1J4U2VyYWNPMnc0bjdiXzE3MTI1ODc5NzI6MTcxMjU5MTU3Ml9WNA)

要注意atomic_t和unsigned int是两个不同的数据类型，第一个类型允许以原子方式修改其值， 即不受并发访问的影响，而第二种类型则是典型的整数。atomic_t是32个比特位，1而在Linux支持的 每种体系结构上整数也是这么多比特位。有人可能企图像下面这样“简化”该定义: 

![img](https://p2onpu7kg4.feishu.cn/space/api/box/stream/download/asynccode/?code=NTI5M2ExYWYzMDQ2YTc4MDI5YmZhMTc5YjNjMmVlNDRfUEZNd0htOXNWcEMzR1RHcnlGeWl0Nk1lSW9KZDNtZE5fVG9rZW46VU5aM2J1SHZ4b1Q2Rkp4QWNQRWNWcThPbklkXzE3MTI1ODc5NzI6MTcxMjU5MTU3Ml9WNA)

这是很糟糕的风格，是内核开发者完全不能接受的。slub代码在访问对象计数器时无需原子性， 而这应该反映在数据类型中。而最重要地，这种“简化”会影响两个子系统中代码的可读性。_mapcount 和inuse则对相应的成员提供了清晰简明的描述，而counter的含义则过于广泛。 

1. ### 数据结构

该结构定义如下: 

![img](https://p2onpu7kg4.feishu.cn/space/api/box/stream/download/asynccode/?code=ODVlOWIwM2UzNjU2ZmRjZDJjMTE5NzE2YTA2NTllMTZfYzlSYTJoVDZPeGVMSGdqNnlydG44ZjBkMlpXeEhLRDlfVG9rZW46TU1vcWJyZUt3b0dTSFp4NWUzUmNKZDRibndiXzE3MTI1ODc5NzI6MTcxMjU5MTU3Ml9WNA)

> slab、freelist和inuse成员用于slub分配器。我们不需要关注这些成员的具体布局，如果内 核编译没有启用slub分配器支持，则不会使用这些成员。为简明起见，我在下文的讨论中会略去这些 成员。 
>
> 该结构的格式是体系结构无关的，不依赖于使用的CPU类型，每个页帧都由该结构描述。除了slub 2 相关成员之外，page结构也包含了若干其他成员，只能在讨论相关内核子系统时准确地解释。尽管需 要引用后续章节，我仍然会概述该结构的内容。 

- **flags**存储了体系结构无关的标志，用于描述页的属性。我将在下文讨论不同的标志选项。 
- **_count**是一个使用计数，表示内核中引用该页的次数。在其值到达0时，内核就知道page实例 当前不使用，因此可以删除。如果其值大于0，该实例决不会从内存删除。如果读者不熟悉引用计数器，可以在附录C查阅更详细的资料。 
- **_mapcount**表示在页表中有多少项指向该页 
- **lru**是一个表头，用于在各种链表上维护该页，以便将页按不同类别分组，最重要的类别是活动和不活动页。第18章中的讨论会特别关注这些链表。 
- 内核可以将多个毗连的页合并为较大的复合页(compound page)。分组中的第一个页称作首页 (head page)，而所有其余各页叫做尾页(tail page)。所有尾页对应的page实例中，都将 **first_page**设置为指向首页。 
- **mapping**指定了页帧所在的地址空间。index是页帧在映射内部的偏移量。地址空间是一个非 常一般的概念， 例如，可以用在向内存读取文件时。地址空间用于将文件的内容(数据)与 装载数据的内存区关联起来。通过一个小技巧，1mapping不仅能够保存一个指针，而且还能 包含一些额外的信息，用于判断页是否属于未关联到地址空间的某个匿名内存区。如果将 mapping置为1，则该指针并不指向address_space的实例，而是指向另一个数据结构 (anon_vma)，该结构对实现匿名页的逆向映射很重要，该结构将在4.11.2节讨论。对该指针的 双重使用是可能的，因为address_space实例总是对齐到sizeof(long)。因此在Linux支持的 所有计算机上，指向该实例的指针最低位总是0。 该指针如果指向address_space实例，则可以直接使用。如果使用了技巧将最低位设置为1， 内核可使用下列操作恢复来恢复指针: ``anon_vma = (struct anon_vma *) (mapping -PAGE_MAPPING_ANON) ``
- **private**是一个指向“私有”数据的指针，虚拟内存管理会忽略该数据。根据页的用途，可以 用不同的方式使用该指针。大多数情况下它用于将页与数据缓冲区关联起来，在后续章节中 描述。 
- **virtual**用于高端内存区域中的页，换言之，即无法直接映射到内核内存中的页。virtual用 于存储该页的虚拟地址。 

**体系结构无关的页标志  flags:**

页的不同属性通过一系列页标志描述，存储为struct page的flags成员中的各个比特位。这些 标志独立于使用的体系结构，因而无法提供特定于CPU或计算机的信息(该信息保存在页表中，见下文可知)。

例如，PG_locked常数定义了标志中用于指定页锁定与否的比特位置。下列宏可以用来操作该 比 特位:  

- PageLocked查询比特位是否置位; 
- SetPageLocked设置PG_locked位，不考虑先前的状态; 
- TestSetPageLocked设置比特位，而且返回原值; 
- ClearPageLocked清除比特位，不考虑先前的状态; 
- TestClearPageLocked清除比特位，返回原值。 

对其他的页标志，同样有一组宏用来操作对应的比特位。这些宏的实现是原子的。尽管其中一些 由若干语句组成，但使用了特殊的处理器命令，确保其行为如同单一的语句。即这些语句是无法中断 的，否则会导致竞态条件。第5章讲述了竞态条件是如何出现的，以及如何防止 

- PG_locked指定了页是否锁定。如果该比特位置位，内核的其他部分不允许访问该页。这防止了内存管理出现竞态条件，例如，在从硬盘读取数据到页帧时。
- 如果在涉及该页的I/O操作期间发生错误，则PG_error置位。 
- PG_referenced和PG_active控制了系统使用该页的活跃程度。在页交换子系统选择换出页时，该信息是很重要的。这两个标志的交互将在第18章解释。 
- PG_uptodate表示页的数据已经从块设备读取，其间没有出错。 
- 如果与硬盘上的数据相比，页的内容已经改变，则置位PG_dirty。出于性能考虑，页并不在每次改变后立即回写。因此内核使用该标志注明页已经改变，可以在稍后刷出。 设置了该标志的页称为脏的(通常，该意味着内存中的数据没有与外存储器介质如硬盘上的 数据同步)。 
- PG_lru有助于实现页面回收和切换。内核使用两个最近最少使用(least recently used，lru)链 表1来区别活动和不活动页。如果页在其中一个链表中，则设置该比特位。还有一个PG_active 标志，如果页在活动页链表中，则设置该标志。第18章详细讨论了这一重要机制。 
- PG_highmem表示页在高端内存中，无法持久映射到内核内存中。 
- 如果page结构的private成员非空，则必须设置PG_private位。用于I/O的页，可使用该字段将页细分为多个缓冲区(更多信息请参见第16章)，但内核的其他部分也有各种不同的方法,将私有数据附加到页上。
- 如果页的内容处于向块设备回写的过程中，则需要设置PG_writeback位。 
- 如果页是3.6节讨论的slab分配器的一部分，则设置PG_slab位。 
- 如果页处于交换缓存，则设置PG_swapcache位。在这种情况下，private包含一个类型为swap_entry_t的项 .
- 在可用内存的数量变少时，内核试图周期性地回收页，即剔除不活动、未用的页。第18章讨论了相关细节。在内核决定回收某个特定的页之后，需要设置PG_reclaim标志通知。 
- 如果页空闲且包含在伙伴系统的列表中，则设置PG_buddy位，伙伴系统是页分配机制的核心。 
- PG_compound表示该页属于一个更大的复合页，复合页由多个毗连的普通页组成。 

内核定义了一些标准宏，用于检查页是否设置了某个特定的比特位，或者操作某个比特位。这些宏的名称有一定的模式，如下所述。

- PageXXX(page)会检查页是否设置了PG_XXX位。例如，PageDirty检查PG_dirty位，而Page-Active检查PG_active位，等等。 
- SetPageXXX在某个比特位没有设置的情况下，设置该比特位，并返回原值。 
- ClearPageXXX无条件地清除某个特定的比特位。 
- TestClearPageXXX清除某个设置的比特位，并返回原值。 

请注意，这些操作的实现是原子的。第5章更详细地讨论了原子的含义。 很多情况下，需要等待页的状态改变，然后才能恢复工作。内核提供了两个辅助函数，对此很有用处: 

```C++
<pagemap.h> 
void wait_on_page_locked(struct page *page);
void wait_on_page_writeback(struct page *page)
```

假定内核的一部分在等待一个被锁定的页面，直至页面解锁。wait_on_page_locked提供了该功 能。该函数的技术实现将在第14章讨论，现在只要知道，在页面锁定的情况下调用该函数，内核将进 入睡眠，就足够了。在页解锁之后，睡眠进程被自动唤醒并继续工作。 

wait_on_page_writeback的工作方式类似，该函数会等待到与页面相关的所有待决回写操作结 束，将页面包含的数据同步到块设备(例如，硬盘)为止。 